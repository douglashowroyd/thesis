\chapter{Parallel method for a congruence by generating pairs}
\label{chap:pairs}

A congruence is a binary relation, and is therefore formally described as a set
of pairs.  In a computational setting, it is rarely practical to keep track of
every pair in a congruence; a congruence on a semigroup of size $n$ contains
$n^2$ pairs in the worst case, and on an infinite semigroup contains an infinite
number of pairs.  A congruence can be described in more concise ways utilising
known theory: for example, taking advantage of its being an equivalence relation
and recording only its equivalence classes; or in the case of a Rees congruence,
storing a generating set for the ideal which defines it.  A variety of different
ways to describe a congruence are explained in Chapter \ref{chap:converting},
along with ways to convert one to another.  However, a congruence is still just
a set of pairs, and by reducing the number of pairs we store, we can describe a
congruence very concisely using them.

A congruence $\rho$ is \textit{generated by} a set of pairs $R$ if it consists
of only the pairs in $R$ along with the pairs required by the axioms of a
congruence (reflexivity, symmetry, transitivity and compatibility).  Thus a
congruence can be described completely by storing only a few pairs.
Indeed, experiments on a range of interesting semigroups in Chapter
\ref{chap:lattice} show that many congruences can be generated by an extremely
small number of generating pairs, and indeed that most of the congruences
studied are principal (generated by a single pair). %TODO: actually do this

Another justification for the use of generating pairs is that it is a completely
generic representation.  Some special types of semigroup have their own abstract
representations of congruences---for inverse semigroups, one can study
kernel-trace pairs; for groups, normal subgroups; for completely simple or
completely 0-simple semigroups, linked triples---but generating pairs can
represent a congruence on any semigroup whatsoever.  Furthermore, a researcher
might be interested in what pairs are implied by a given pair or set of pairs in
a congruence, and this representation can answer such questions.

Left congruences and right congruences can also be described using generating
pairs, and some algorithms designed for two-sided congruences can be used with
minor modifications to compute information about left and right congruences.

This chapter describes a parallelised approach for computing a congruence from a
set of generating pairs, as implemented in \texttt{libsemigroups}
\cite{libsemigroups}.  First we will give a general outline of the system
and what questions it hopes to answer, then we will describe in detail each
algorithms used, its advantages and disadvantages, and when it can be applied.
Finally we will explain how the different algorithms are executed together, and
consider their implementation in \cite{libsemigroups}.

\section{Why Parallelisation?}

Parallel processing has seen major advances in the last ten years, with
multi-core processors becoming the norm in many types of computers, and
processors with 4, 8, or even 16 cores becoming common on a desktop PC.  This
being the case, it is desirable to parallelise mathematical algorithms wherever
possible, and take advantage of the ability to execute multiple
threads of instructions concurrently.  Some algorithms, such as simple binary
searches, are ``embarrassingly parallel''---that is, they can be split into
independent threads which require almost no communication with each other.
These are suited so well to parallelisation that splitting the operation into
$n$ parallel threads reduces the expected run-time to barely more than
$\frac{1}{n}$ what it would be when run in a single thread.  Other
algorithms do not parallelise so well: sometimes threads have to communicate, or
use shared resources, causing significant slowdown and severely limiting the
improvements which can be made by parallelising.

When it comes to computing information about a congruence from generating pairs,
there are various different approaches which can be taken: in Sections
\ref{sec:tc}, \ref{sec:kbfp} and \ref{sec:p}, we describe three
possible algorithms.  Depending on what sort of semigroup is described, several
or all of these might be appropriate.  However, depending on certain properties
of the congruence, one might perform far better than another.  For example, the
pair orbit algorithm works well on congruences which contain few non-reflexive
pairs, while the Todd-Coxeter algorithm tends to work well on congruences with
few classes (i.e.~very many pairs).  Given only a set of generating pairs, these
properties may be unknown in advance, which makes it difficult to choose a good
algorithm.

The natural answer to this problem is the core concept of this chapter: a
parallel approach which does not attempt to parallelise individual algorithms,
but which runs all known algorithms at the same time, each in a different
thread, and simply halts all threads as soon as any one completes.  Since these
algorithms do not interact with each other in any way, the total run-time will
be close to the minimum run-time of all the different algorithms.  This is
particularly important, since some of the algorithms never terminate for certain
semigroups and congruences (for example, those of infinite size).

\section{Applicable types of semigroup}

The type of element in a semigroup affects which methods will be most effective,
or even which methods will be applicable.  For this purpose, we divide
semigroups into two categories: finitely presented semigroups, and
\textit{concrete} semigroups.  By \textit{concrete}, we mean a finite semigroup
whose elements can be multiplied and compared quickly, without reference to the
semigroup as a whole; these could be semigroups of transformations, partial
permutations, bipartitions, matrices, or other finite objects.  Their elements
will be known in advance.  Finitely presented semigroups are a different case,
in that their elements are not known in advance, and indeed it may not be known
whether or not they are finite.  Finitely presented monoids are treated as
equivalent to finitely presented semigroups, since a semigroup presentation can
be attained by simply adding a generator for the identity and relations to make
it multiplicatively neutral.

\section{Questions}

Each method we are about to explain can provide a variety of information, but it
is important to consider which questions we aim to answer.  Our system should be
able to return the following information about a given congruence when
requested:

\begin{itemize}
\item Presence of a given pair $(x,y)$
\item Number of congruence classes
\item The elements in each non-trivial congruence class
\item Class number of a given element
\end{itemize}

Note that for finitely presented semigroups, these questions may be
undecidable.  In the case that a question is decidable, our approach should
return an answer in finite time.

\section{Finding a presentation}

Where do we get the presentation from in the first place?

\section{The methods}

\subsection{Pair orbit enumeration}
\label{sec:p}

Background

The P algorithm

Using Knuth-Bendix: KBP

Semigroups/congs it works/works best on

Complexity

\subsection{Todd-Coxeter}
\label{sec:tc}

The Todd-Coxeter algorithm, was originally described in 1936 in
\cite{todd_coxeter_1936}.  It was an algorithm to enumerate the cosets of a
finitely generated subgroup of a finitely presented group.  Arriving before the
advent of electronic computers, the algorithm was originally intended to be
carried out by hand.  Perhaps the earliest automatic implementation was on the
EDSAC II computer in Cambridge \cite{leech_1963}.  Since then, a wide variety of
efficient, optimised versions have been implemented, for example \cite{ace}.

A variation of Todd-Coxeter for semigroups was described in 1967
\cite{neumann_1967}.  The algorithm takes a presentation $\langle X | R \rangle$
for a semigroup $S$ and computes the right regular representation of $S^1$ with
respect to the generators $X$---that is, it computes all the elements of $S$ and
the result of right-multiplying each element by each generator.  Since the
original algorithm makes very little use of those properties unique to groups,
there are not many modifications required in order to apply the method to
semigroups.  Other descriptions of Todd-Coxeter for semigroups can be found in
\cite[ch.~12]{ruskuc_thesis} and \cite[ch.~1.2]{walker_thesis}, and a variation
specific to inverse semigroups can be found in \cite{cutting_thesis}.  A good
implementation, which our version follows closely, is found in
\cite[\texttt{lib/tcsemi.gi}]{gap}, and is based on \cite{walker_thesis}.

We will now describe the Todd-Coxeter method as used in the context of this
chapter, while emphasising that this does not represent significant new work.

\subsubsection{Setup}

The Todd-Coxeter algorithm is based on a table, where each row corresponds to a
single congruence class (or equivalently, a single element of the quotient
semigroup).  The columns of the table correspond to the generators of the
semigroup, and the entry in row $i$, column $j$ represents the element found by
taking element $i$ and right-multiplying it by generator $j$.  These entries may
be blank, and two different rows may be found to describe the same element.

Suppose we have a semigroup presentation $\langle X | R \rangle$.  The table is
initialised with a single row, numbered $1$, representing the identity.  If we
are dealing with a monoid presentation, this will be the identity of that
monoid, corresponding to the empty word $\varepsilon$; if instead we have just a
semigroup presentation, then this row should be treated as an appended identity,
to be ignored or discarded after the algorithm is completed.  The row is empty,
containing a blank entry in all $|X|$ columns.

Rows will be added to the table, and deleted from it.  A list must be kept of
rows which are in use; when a row is added, its position in the table should be
appended to this list at the end, and when a row is deleted it should be removed
from its position in the list and added to a list of ``free rows'' which can be
reused later.  The ``rows in use'' list is best implemented as a doubly-linked
list, so that single entries can be added and removed with as little processor
work as possible.

\subsubsection{The three operations}

The following 3 operations may now be applied to the table.

\begin{itemize}
\item \textsc{Add}: Fill in a blank entry and add a row to the table;
\item \textsc{Trace}: Trace a relation from a row;
\item \textsc{Coinc}: Process a coincidence.
\end{itemize}

The first operation, \textsc{Add}, is simple.  A blank cell is found in the
table, and a new row is added at the bottom.  The number of the new row is then
written into the blank cell.

\begin{algorithm}
\caption{The \textsc{Add} algorithm}
\label{alg:add}
\begin{algorithmic}[1]
\Procedure{Add}{$row, col$}
\State $i \gets \text{an unused row number}$
\State $table[i] \gets \text{a blank row}$
\State Append $i$ to $used$
\State $table[row][col] \gets i$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\textsc{Trace} takes two arguments: a relation $v=w$ from $R$, and a row $r$
in the table.  We start from row $r$, and process $v$ one letter at a time: we
find the column corresponding to the letter, and look at that position in the
table; this gives us the number of the new row which we move to.  If we
encounter a blank entry before the final letter, we apply \textsc{Add} to that
cell, and follow the new entry.  At the end of the process we have an entry in
the table, blank or filled, which we will call $r \cdot v$.  We repeat the
process with the other word to find $r \cdot w$.

To satisfy the relation, we need to set these two entries such that
$r \cdot v = r \cdot w$.
\begin{itemize}
\item If $r \cdot v$ and $r \cdot w$ are both blank, then we apply
  \textsc{Add} to $r \cdot v$ and copy the entry into $r \cdot w$.
\item If just one of the entries is filled, then the filled entry is copied into
  the blank one.
\item If both entries are filled and equal, we need do nothing.
\item If both entries are filled and are distinct, we apply \textsc{Coinc} to
  the two entries.
\end{itemize}

\begin{algorithm}
\caption{The \textsc{Trace} algorithm (we write $a \cdot x$ for $table[a][x]$)}
\label{alg:trace}
\begin{algorithmic}[1]
\Procedure{Trace}{$r, v = w$}
\State Write $v = v_1 \dots v_m$ \Comment $(v_i \in X \text{~for~} 1 \leq i \leq m)$
\State Write $w = w_1 \dots w_n$ \Comment $(w_i \in X \text{~for~} 1 \leq i \leq n)$
\State $s \gets r$
\For{$i \in \{1, \dots, m-1\}$}
  \If{$s \cdot v_i = \varepsilon$}
    \State \Call{Add}{$s, v_i$}
  \EndIf
  \State $s \gets s \cdot v_i$
\EndFor
\State $t \gets r$
\For{$i \in \{1, \dots, n-1\}$}
  \If{$t \cdot w_i = \varepsilon$}
    \State \Call{Add}{$t, w_i$}
  \EndIf
  \State $t \gets t \cdot w_i$
\EndFor

\If{$s \cdot v_m = t \cdot w_n = \varepsilon$}
  \State \Call{Add}{$s, v_m$}
  \State $t \cdot w_n \gets s \cdot v_m$
\ElsIf{$s \cdot v_m = \varepsilon$}
  \State $s \cdot v_m \gets t \cdot w_n$
\ElsIf{$t \cdot w_n = \varepsilon$}
  \State $t \cdot w_n \gets s \cdot v_m$
\ElsIf{$s \cdot v_m \neq t \cdot w_n$}
  \State \Call{Coinc}{$s \cdot v_m, t \cdot w_n$}
\EndIf

\EndProcedure
\end{algorithmic}
\end{algorithm}

\textsc{Coinc} is used when two rows in the table are found to refer to the same
element.  The two rows are combined into one, with all known information being
preserved.  The higher-numbered row is deleted, and all occurrences of the
higher number in the table are replaced by the lower number.  This may imply
that another pair of rows are equal, another coincidence that should be
processed by a recursive call to \textsc{Coinc} (or should be stored in a list
for processing after this call is finished).

\begin{algorithm}
\caption{The \textsc{Coinc} algorithm (we write $a \cdot x$ for $table[a][x]$)}
\label{alg:coinc}
\begin{algorithmic}[1]
\Procedure{Coinc}{$r, s$}
\State wlog let $r < s$
\For{$i \in \left\{1, \dots, |X|\right\}$}
  \If{$r \cdot i = \varepsilon$}
    \State $r \cdot i \gets s \cdot i$
  \ElsIf{$r \cdot i \neq s \cdot i \neq \varepsilon$}
    \State \Call{Coinc}{$r \cdot i, s \cdot i$}
  \EndIf
\EndFor
\State Remove $s$ from $used$
\For{$\rho \in used$}
  \For{$i \in \left\{1, \dots, |X|\right\}$}
    \If{$\rho \cdot i = s$}
      \State $\rho \cdot i \gets r$
    \EndIf
  \EndFor
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

Now that we have these three operations, it is simple to describe the overall
algorithm.  We go through the list of used rows, starting with row $1$.  To each
of these rows we apply each relation from $R$, using \textsc{Trace}.  Each call
to \textsc{Trace} may, of course, invoke calls to \textsc{Add} and
\textsc{Coinc}, so rows will be appended to the list as the algorithm
progresses.  When the end of the list is reached, the table should be a Cayley
graph for the finitely presented semigroup (excluding the identity row $1$).
Note that the end of the list is not guaranteed to be reached, for example in
the case of an infinite semigroup whose table would grow indefinitely.  In this
case, the procedure would run forever.

\begin{algorithm}
\caption{The \textsc{Todd-Coxeter} algorithm for semigroups}
\label{alg:tc}
\begin{algorithmic}[1]
\Procedure{Todd-Coxeter}{$\langle X | R \rangle$}
\State $table \gets $ $1$ blank row with $|X|$ columns
\State $used \gets (1)$
\For{$row \in used$}
  \For{$rel \in R$}
    \State \Call{Trace}{$row, rel$}
  \EndFor
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsubsection{An example}
We now give an example of the Todd-Coxeter algorithm running on the semigroup
presentation
$$\langle a, b | a^2=a, ba=a, b^3=b, ab^2=a \rangle.$$
We initialise the table to look like Table \ref{tab:tc1}:
\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c |}
    \multicolumn{1}{c}{} &
    \multicolumn{1}{c}{$a$} &
    \multicolumn{1}{c}{$b$} \\
    \cline{2-3}
    1 & & \\
    \cline{2-3}
  \end{tabular}
  \caption{Initial position}
  \label{tab:tc1}
\end{table}
the $used$ list contains only a single entry, $1$.  We begin by tracing each
relation on the row $1$, starting with $a^2=a$.  This relation makes us call
\textsc{Add} on the cell $1 \cdot a$, creating a new row, $2$, which is added to
$used$.  At the end of the \textsc{Trace}, we must set $2 \cdot a$ to $1 \cdot
a$, so we write $2$ into $2 \cdot a$ (as in Table \ref{tab:tc2}).
\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c |}
    \multicolumn{1}{c}{} &
    \multicolumn{1}{c}{$a$} &
    \multicolumn{1}{c}{$b$} \\
    \cline{2-3}
    1 & 2 & \\
    \cline{2-3}
    2 & 2 & \\
    \cline{2-3}
  \end{tabular}
  \caption{Position after \textsc{Trace}($1, a^2=a$)}
  \label{tab:tc2}
\end{table}

Next, we apply \textsc{Trace}($1, ba=a$) and we must \textsc{Add} a new row for
$1 \cdot b$.  After \textsc{Trace}, the new row also contains $2$ in the $a$
column.
\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c |}
    \multicolumn{1}{c}{} &
    \multicolumn{1}{c}{$a$} &
    \multicolumn{1}{c}{$b$} \\
    \cline{2-3}
    1 & 2 & 3 \\
    \cline{2-3}
    2 & 2 & \\
    \cline{2-3}
    3 & 2 & \\
    \cline{2-3}
  \end{tabular}
  \caption{Position after \textsc{Trace}($1, ba=a$)}
  \label{tab:tc3}
\end{table}

Still on row $1$, we apply \textsc{Trace} to the third relation, $b^3=b$.  This
creates a new row for $1 \cdot b \cdot b = 3 \cdot b = 4$.  The new row's $b$
entry is set to be the same as $1 \cdot b$.
\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c |}
    \multicolumn{1}{c}{} &
    \multicolumn{1}{c}{$a$} &
    \multicolumn{1}{c}{$b$} \\
    \cline{2-3}
    1 & 2 & 3 \\
    \cline{2-3}
    2 & 2 & \\
    \cline{2-3}
    3 & 2 & 4 \\
    \cline{2-3}
    4 &  & 3 \\
    \cline{2-3}
  \end{tabular}
  \caption{Position after \textsc{Trace}($1, ab^2=a$)}
  \label{tab:tc4}
\end{table}

The final relation for row $1$ is $ab^2=a$.  A new row is added for $1 \cdot a
\cdot b$, and its $b$ entry is set equal to $1 \cdot a = 2$ (as in Table
\ref{tab:tc5}).
\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c |}
    \multicolumn{1}{c}{} &
    \multicolumn{1}{c}{$a$} &
    \multicolumn{1}{c}{$b$} \\
    \cline{2-3}
    1 & 2 & 3 \\
    \cline{2-3}
    2 & 2 & 5 \\
    \cline{2-3}
    3 & 2 & 4 \\
    \cline{2-3}
    4 &  & 3 \\
    \cline{2-3}
    5 & & 2 \\
    \cline{2-3}
  \end{tabular}
  \caption{Position after \textsc{Trace}($1, ab^2=a$)}
  \label{tab:tc5}
\end{table}

We have now finished with row $1$, and we proceed to the next row in the $used$
list, which is $2$.  Accordingly, we apply the first relation,
\textsc{Trace}($2, a^2=a$).  Since $2 \cdot a$ and $2 \cdot a \cdot a$ are both
already set to $2$, we do nothing.  \textsc{Trace}($2, ba=a$) is more fruitful,
setting $2 \cdot b \cdot a$ (that is, $5 \cdot a$) to $2$.  The last two
relations make no changes to the table, and we have Table \ref{tab:tc6}.
\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c |}
    \multicolumn{1}{c}{} &
    \multicolumn{1}{c}{$a$} &
    \multicolumn{1}{c}{$b$} \\
    \cline{2-3}
    1 & 2 & 3 \\
    \cline{2-3}
    2 & 2 & 5 \\
    \cline{2-3}
    3 & 2 & 4 \\
    \cline{2-3}
    4 &  & 3 \\
    \cline{2-3}
    5 & 2 & 2 \\
    \cline{2-3}
  \end{tabular}
  \caption{Position after all relations on row $2$}
  \label{tab:tc6}
\end{table}

Now we proceed to row $3$, applying each relation with \textsc{Trace}.  The only
relation which affects the table is $ba=a$,
which sets $4 \cdot a$ to the value of $3 \cdot a$ (which is $2$).
All the relations are applied to rows $4$ and $5$, with no modification made to
the table.  We end up with a completely filled table, as shown in Table
\ref{tab:tc7}.
\begin{table}[H]
  \centering
  \begin{tabular}{c | c | c |}
    \multicolumn{1}{c}{} &
    \multicolumn{1}{c}{$a$} &
    \multicolumn{1}{c}{$b$} \\
    \cline{2-3}
    1 & 2 & 3 \\
    \cline{2-3}
    2 & 2 & 5 \\
    \cline{2-3}
    3 & 2 & 4 \\
    \cline{2-3}
    4 & 2 & 3 \\
    \cline{2-3}
    5 & 2 & 2 \\
    \cline{2-3}
  \end{tabular}
  \caption{Position after completion}
  \label{tab:tc7}
\end{table}

We can now delete row $1$, which acts as an appended identity, and we find a
description of the semigroup's multiplication, with relation to its generators.
It is isomorphic to the full transformation semigroup $\mathcal{T}_2$, where $a$
is a constant map and $b$ is the transposition.
\begin{figure}[H]
  \centering
  \begin{dot2tex}
    //dot
    digraph {
      rankdir=LR
      node [shape=circle]
      2
      3
      4
      5
      2 -> 2 [label=a]
      2 -> 5 [label=b, dir=both]
      3 -> 2 [label=a]
      3 -> 4 [label=b, dir=both]
      4 -> 2 [label=a]
      5 -> 2 [label=a]
    }
  \end{dot2tex}
  \caption{Cayley graph of the semigroup}
  \label{fig:tc-cayley-graph}
\end{figure}

\subsubsection{Improvements}
Left/right congruences

The pack phase

Pre-filling the table

Semigroups/congs it works/works best on

Complexity

\subsection{Knuth-Bendix and Froidure-Pin}
\label{sec:kbfp}

Background

The KBFP algorithm

Semigroups/congs it works/works best on

Complexity

\section{Running in parallel}

How do we tie together all the different algorithms?

\section{Implementation}

Practical considerations in libsemigroups

Showing off speed

Drawbacks
